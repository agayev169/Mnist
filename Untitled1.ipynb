{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-b06e5b635d68>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Cost: 6182.5327\n",
      "Accuracy: 0.094333336\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 6117.533\n",
      "Accuracy: 0.114\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 5599.5176\n",
      "Accuracy: 0.09633333\n",
      "Best cost so far\n",
      "Cost: 4566.2485\n",
      "Accuracy: 0.13\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 3251.4805\n",
      "Accuracy: 0.14066666\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 2292.0464\n",
      "Accuracy: 0.13533333\n",
      "Best cost so far\n",
      "Cost: 1576.127\n",
      "Accuracy: 0.12066667\n",
      "Best cost so far\n",
      "Cost: 1289.4702\n",
      "Accuracy: 0.147\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 1478.0312\n",
      "Accuracy: 0.15233333\n",
      "Best accuracy so far\n",
      "Cost: 1087.8802\n",
      "Accuracy: 0.11266667\n",
      "Best cost so far\n",
      "Cost: 992.79\n",
      "Accuracy: 0.14733334\n",
      "Best cost so far\n",
      "Cost: 759.0198\n",
      "Accuracy: 0.23033333\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 803.80396\n",
      "Accuracy: 0.24433333\n",
      "Best accuracy so far\n",
      "Cost: 496.13635\n",
      "Accuracy: 0.25966668\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 461.2657\n",
      "Accuracy: 0.24333334\n",
      "Best cost so far\n",
      "Cost: 403.93652\n",
      "Accuracy: 0.31366667\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 310.55573\n",
      "Accuracy: 0.38233334\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 332.2613\n",
      "Accuracy: 0.41033334\n",
      "Best accuracy so far\n",
      "Cost: 314.3402\n",
      "Accuracy: 0.42133334\n",
      "Best accuracy so far\n",
      "Cost: 273.05093\n",
      "Accuracy: 0.43933332\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 259.1433\n",
      "Accuracy: 0.39766666\n",
      "Best cost so far\n",
      "Cost: 238.73465\n",
      "Accuracy: 0.44233334\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 195.27399\n",
      "Accuracy: 0.41666666\n",
      "Best cost so far\n",
      "Cost: 223.19272\n",
      "Accuracy: 0.465\n",
      "Best accuracy so far\n",
      "Cost: 192.18123\n",
      "Accuracy: 0.43033335\n",
      "Best cost so far\n",
      "Cost: 127.49676\n",
      "Accuracy: 0.53466666\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 179.26038\n",
      "Accuracy: 0.543\n",
      "Best accuracy so far\n",
      "Cost: 124.75041\n",
      "Accuracy: 0.5453333\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 106.08019\n",
      "Accuracy: 0.6\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 128.42398\n",
      "Accuracy: 0.61333334\n",
      "Best accuracy so far\n",
      "Cost: 93.934525\n",
      "Accuracy: 0.60066664\n",
      "Best cost so far\n",
      "Cost: 129.4688\n",
      "Accuracy: 0.63266665\n",
      "Best accuracy so far\n",
      "Cost: 108.308174\n",
      "Accuracy: 0.654\n",
      "Best accuracy so far\n",
      "Cost: 73.27382\n",
      "Accuracy: 0.6586667\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 49.917812\n",
      "Accuracy: 0.7\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 63.312855\n",
      "Accuracy: 0.7403333\n",
      "Best accuracy so far\n",
      "Cost: 51.45665\n",
      "Accuracy: 0.7643333\n",
      "Best accuracy so far\n",
      "Cost: 42.54868\n",
      "Accuracy: 0.796\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 31.17454\n",
      "Accuracy: 0.792\n",
      "Best cost so far\n",
      "Cost: 44.313843\n",
      "Accuracy: 0.80266666\n",
      "Best accuracy so far\n",
      "Cost: 23.341036\n",
      "Accuracy: 0.836\n",
      "Best cost so far\n",
      "Best accuracy so far\n",
      "Cost: 29.528082\n",
      "Accuracy: 0.843\n",
      "Best accuracy so far\n",
      "Cost: 22.873245\n",
      "Accuracy: 0.831\n",
      "Best cost so far\n",
      "Cost: 19.264908\n",
      "Accuracy: 0.8146667\n",
      "Best cost so far\n",
      "Cost: 24.19318\n",
      "Accuracy: 0.85966665\n",
      "Best accuracy so far\n",
      "Cost: 33.683327\n",
      "Accuracy: 0.86433333\n",
      "Best accuracy so far\n",
      "Cost: 27.716068\n",
      "Accuracy: 0.874\n",
      "Best accuracy so far\n",
      "Cost: 28.435915\n",
      "Accuracy: 0.87766665\n",
      "Best accuracy so far\n",
      "Cost: 18.425053\n",
      "Accuracy: 0.862\n",
      "Best cost so far\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "n_input = 784\n",
    "n_classes = 10\n",
    "lr = 0.01\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# keep_rate = 0.8\n",
    "# keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def maxpool2d(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def convolutional_neural_network(x):\n",
    "\tweights = {'conv1': tf.Variable(tf.random_normal([3, 3, 1, 16])),\n",
    "\t\t\t   'conv2': tf.Variable(tf.random_normal([3, 3, 16, 16])),\n",
    "\t\t\t   'conv3': tf.Variable(tf.random_normal([3, 3, 16, 32])),\n",
    "\t\t\t   'conv4': tf.Variable(tf.random_normal([3, 3, 32, 32])),\n",
    "\t\t\t   'fc1': tf.Variable(tf.random_normal([7*7*32, 256])),\n",
    "\t\t\t   'fc2': tf.Variable(tf.random_normal([256, 100])),\n",
    "\t\t\t   'fc3': tf.Variable(tf.random_normal([100, 100])),\n",
    "\t\t\t   'out': tf.Variable(tf.random_normal([100, n_classes]))}\n",
    "\n",
    "\tbiases = {'conv1': tf.Variable(tf.random_normal([16])),\n",
    "\t\t\t  'conv2': tf.Variable(tf.random_normal([16])),\n",
    "\t\t\t  'conv3': tf.Variable(tf.random_normal([32])),\n",
    "\t\t\t  'conv4': tf.Variable(tf.random_normal([32])),\n",
    "\t\t\t  'fc1': tf.Variable(tf.random_normal([256])),\n",
    "\t\t\t  'fc2': tf.Variable(tf.random_normal([100])),\n",
    "\t\t\t  'fc3': tf.Variable(tf.random_normal([100])),\n",
    "\t\t\t  'out': tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "\tx = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "\tconv1 = tf.nn.relu(conv2d(x, weights['conv1']) + biases['conv1'])\n",
    "\tconv1 = tf.nn.lrn(conv1)\n",
    "\n",
    "\tconv2 = tf.nn.relu(conv2d(conv1, weights['conv2']) + biases['conv2'])\n",
    "\tconv2 = maxpool2d(conv2)\n",
    "\tconv2 = tf.nn.lrn(conv2)\n",
    "\n",
    "\tconv3 = tf.nn.relu(conv2d(conv2, weights['conv3']) + biases['conv3'])\n",
    "\tconv3 = tf.nn.lrn(conv3)\n",
    "\n",
    "\tconv4 = tf.nn.relu(conv2d(conv3, weights['conv4']) + biases['conv4'])\n",
    "\tconv4 = maxpool2d(conv4)\n",
    "\tconv4 = tf.nn.lrn(conv4)\n",
    "\n",
    "\tfc1 = tf.reshape(conv4, [-1, 7*7*32])\n",
    "\tfc1 = tf.nn.relu(tf.matmul(fc1, weights['fc1']) + biases['fc1'])\n",
    "\n",
    "\tfc2 = tf.nn.relu(tf.matmul(fc1, weights['fc2']) + biases['fc2'])\n",
    "\n",
    "\tfc3 = tf.nn.relu(tf.matmul(fc2, weights['fc3']) + biases['fc3'])\n",
    "\n",
    "\treturn tf.matmul(fc3, weights['out']) + biases['out']\n",
    "\n",
    "train = convolutional_neural_network(x)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = train, labels = y))\n",
    "optimizer = tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(tf.nn.softmax(train), 1), tf.argmax(y, 1)), tf.float32))\n",
    "\n",
    "costs = []\n",
    "accs  = []\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep = None)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\tsess.run(init)\n",
    "\n",
    "\t# for i in range(1, 4):\n",
    "\t# saver.restore(sess, \"models/model\" + str(i) + \".ckpt\")\n",
    "\n",
    "\t# saver.restore(sess, \"models/cnn_3/model93.ckpt\")\n",
    "\t# print(\"Model restored\")\n",
    "\n",
    "\t# acc_sum = 0\n",
    "\t# for _ in range(int(len(mnist.test.images) / 1000)):\n",
    "\t# \txs, ys = mnist.test.next_batch(1000)\n",
    "\t# \tacc_in = sess.run(acc, feed_dict = {x: xs, y: ys})\n",
    "\t# \tacc_sum += acc_in\n",
    "\n",
    "\t# print(acc_sum / (len(mnist.test.images) / 1000))\n",
    "\n",
    "\t# print(sess.run(train, feed_dict = {x: xs, y: ys}))\n",
    "\t# print(sess.run(pred, feed_dict = {x: xs, y: ys}))\n",
    "\t# print(ys)\n",
    "\t# print(sess.run(tf.argmax(train, 1), feed_dict = {x: xs, y: ys}))\n",
    "\t# print(sess.run(tf.argmax(ys, 1)))\n",
    "\t# print(sess.run(acc, feed_dict = {x: xs, y: ys}))\n",
    "\n",
    "\tepochs = 20\n",
    "\tbatch_size = 128\n",
    "\n",
    "\tcost_min = 1000000\n",
    "\tcost_min_index = 0\n",
    "\tacc_max = 0\n",
    "\tacc_max_index = 0\n",
    "\tsave_count = 1\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tepoch_time = time.clock_gettime(0);\n",
    "\t\tepoch_max_acc = 0\n",
    "\t\tfor i in range(int(len(mnist.train.images) / batch_size)):\n",
    "\t\t\txs, ys = mnist.train.next_batch(batch_size)\n",
    "\t\t\tsess.run(optimizer, feed_dict = {x: xs, y: ys})\n",
    "\t\t\tc = sess.run(cost, feed_dict = {x: xs, y: ys})\n",
    "\t\t\tcosts.append(c)\n",
    "\t\t\txs, ys = mnist.test.next_batch(3000)\n",
    "\t\t\taccur = sess.run(acc, feed_dict = {x: xs, y: ys})\n",
    "\t\t\taccs.append(accur)\n",
    "\n",
    "\t\t\tif (accur > epoch_max_acc):\n",
    "\t\t\t\tepoch_max_acc = accur\n",
    "\t\t\tif c < cost_min or accur > acc_max:\n",
    "# \t\t\t\tsave_path = saver.save(sess, \"models/cnn_5/model\" + str(save_count) + \".ckpt\")\n",
    "\t\t\t\tprint(\"Cost:\", c)\n",
    "\t\t\t\tprint(\"Accuracy:\", accur)\n",
    "\t\t\t\tsave_count += 1\n",
    "\t\t\t\tif c < cost_min:\n",
    "\t\t\t\t\tprint(\"Best cost so far\")\n",
    "\t\t\t\t\tcost_min = c\n",
    "\t\t\t\t\tcost_min_index = save_count - 1\n",
    "\t\t\t\tif acc_max < accur:\n",
    "\t\t\t\t\tprint(\"Best accuracy so far\")\n",
    "\t\t\t\t\tacc_max = accur\n",
    "\t\t\t\t\tacc_max_index = save_count - 1\n",
    "# \t\t\t\tprint(\"Model saved in path: %s\\n\" % save_path)\n",
    "\n",
    "\t\tprint(\"Results after epoch #\" + str(epoch + 1) + \"/\" + str(epochs))\n",
    "\t\tprint(\"Max average in this epoch:\", epoch_max_acc)\n",
    "\t\tprint(\"cost_min = %f at %i, acc_max = %f at %i\" \n",
    "\t\t\t%(cost_min, cost_min_index, acc_max, acc_max_index))\n",
    "\t\tprint(\"Time spent for epoch:\", time.clock_gettime(0) - epoch_time, \"\\n\\n\")\n",
    "# \t\tfile = open(\"models/cnn_5/info\", 'a')\n",
    "# \t\tfile.write(\"cost_min = %f at %i, acc_max = %f at %i\\n\" \n",
    "# \t\t\t%(cost_min, cost_min_index, acc_max, acc_max_index))\n",
    "# \t\tfile.close()\n",
    "\n",
    "\tprint(\"Training is over\")\n",
    "\n",
    "# \tplt.plot(costs, label = \"Cost\")\n",
    "# \tplt.plot(accs, label = \"Accuracy\")\n",
    "# \tplt.legend()\n",
    "# \tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spell - Mnist on K80",
   "language": "",
   "name": "spell_aa08819a"
  },
  "language_info": {
   "codemirror_mode": "python",
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
